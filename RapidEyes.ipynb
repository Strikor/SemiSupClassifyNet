{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92d86098-6daa-4564-abc4-0d9e96b7548c",
      "metadata": {
        "id": "92d86098-6daa-4564-abc4-0d9e96b7548c"
      },
      "source": [
        "# 1. Setup & Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b3e2cf7-c055-41e1-b5d3-d7bc819cd0f3",
      "metadata": {
        "id": "3b3e2cf7-c055-41e1-b5d3-d7bc819cd0f3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import math\n",
        "import umap\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
        "import hdbscan\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "#Hyperparameters\n",
        "BATCH_SIZE = 256\n",
        "LR = 1e-3\n",
        "EPOCHS_SIMCLR = 50     #Warmup\n",
        "#Using rounded to balance between hard rounds and random rounds\n",
        "TOTAL_TRIPLET_EPOCHS = 50\n",
        "MARGIN = 1.0           #Distance between nodes needed to be clustered\n",
        "RANDOM_EPOCHS_PER_CYCLE = 5\n",
        "HARD_EPOCHS_PER_CYCLE = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8097ade9-8aa3-45e9-8d9e-ef3b6c910e08",
      "metadata": {
        "id": "8097ade9-8aa3-45e9-8d9e-ef3b6c910e08"
      },
      "source": [
        "# 2. Data Loading & Transformations (CIFAR-100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "111601b0-5554-461b-83ae-c8903ef75807",
      "metadata": {
        "id": "111601b0-5554-461b-83ae-c8903ef75807"
      },
      "outputs": [],
      "source": [
        "#Define pre-processing transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "simclr_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "#Dataset\n",
        "train_dataset_raw = datasets.CIFAR100(\n",
        "    root=\"./data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=train_transform\n",
        ")\n",
        "test_dataset_raw = datasets.CIFAR100(\n",
        "    root=\"./data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=test_transform\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51824877-31db-4b39-9b12-142dd62f7502",
      "metadata": {
        "id": "51824877-31db-4b39-9b12-142dd62f7502"
      },
      "source": [
        "# 3. Self-Supervised Warm-Up (SimCLR-like)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "aed67d1b-7357-4bfd-8375-005e3c1f4e9f",
      "metadata": {
        "id": "aed67d1b-7357-4bfd-8375-005e3c1f4e9f"
      },
      "outputs": [],
      "source": [
        "class SimCLRDataset(Dataset):\n",
        "    #Takes the same image and mutates it in some way\n",
        "    #While telling the network they're the same\n",
        "    #Pulls out general features\n",
        "    def __init__(self, base_dataset, transform=None, second_transform=None):\n",
        "        super().__init__()\n",
        "        self.base_dataset = base_dataset\n",
        "        self.transform = transform\n",
        "        self.second_transform = second_transform if second_transform else transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raw_img = self.base_dataset.data[idx]\n",
        "        pil_img = Image.fromarray(raw_img)\n",
        "        img1 = self.transform(pil_img)\n",
        "        img2 = self.second_transform(pil_img)\n",
        "        return img1, img2\n",
        "\n",
        "\n",
        "class SimpleConvBase(nn.Module):\n",
        "    #Extremely basic CNN, probably need to make it more complex for better results\n",
        "    def __init__(self, out_dim=128):\n",
        "        super(SimpleConvBase, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  #16x16\n",
        "\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),  #8x8\n",
        "\n",
        "            nn.Conv2d(64, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1,1))\n",
        "        )\n",
        "        self.fc = nn.Linear(128, out_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SimCLRModel(nn.Module):\n",
        "    #Adds a projection head to the existing CNN to allow contrastive loss to function better\n",
        "    def __init__(self, base_out_dim=128, projection_dim=64):\n",
        "        super(SimCLRModel, self).__init__()\n",
        "        self.encoder = SimpleConvBase(out_dim=base_out_dim)\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(base_out_dim, base_out_dim),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(base_out_dim, projection_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.encoder(x)\n",
        "        proj = self.projection(feat)\n",
        "        return feat, proj\n",
        "\n",
        "\n",
        "def nt_xent_loss(z_i, z_j, temperature=0.5):\n",
        "    #NT-Xent is a special loss function used to facilitate\n",
        "    #Moving samples toward or away from one another\n",
        "    batch_size = z_i.size(0)\n",
        "    z_i = F.normalize(z_i, dim=1)\n",
        "    z_j = F.normalize(z_j, dim=1)\n",
        "\n",
        "    logits = torch.matmul(z_i, z_j.t()) / temperature\n",
        "    labels = torch.arange(batch_size).long().to(z_i.device)\n",
        "\n",
        "    loss_i = F.cross_entropy(logits, labels)\n",
        "    loss_j = F.cross_entropy(logits.t(), labels)\n",
        "    return (loss_i + loss_j) / 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b96956d-3ee6-4f81-bb80-45a6694b49e8",
      "metadata": {
        "id": "3b96956d-3ee6-4f81-bb80-45a6694b49e8"
      },
      "source": [
        "# 4. SimCLR Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0db5937c-ac78-4dc7-87ce-d2430167ce9a",
      "metadata": {
        "id": "0db5937c-ac78-4dc7-87ce-d2430167ce9a"
      },
      "outputs": [],
      "source": [
        "#SimCLR function\n",
        "def train_simclr_epoch(model, loader, optimizer, epoch, temperature=0.5):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for img1, img2 in loader:\n",
        "        img1 = img1.to(device)\n",
        "        img2 = img2.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        _, z1 = model(img1)\n",
        "        _, z2 = model(img2)\n",
        "\n",
        "        loss = nt_xent_loss(z1, z2, temperature=temperature)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    print(f\"[SimCLR E{epoch}] Loss={avg_loss:.4f}\")\n",
        "    return avg_loss\n",
        "\n",
        "\n",
        "simclr_dataset = SimCLRDataset(\n",
        "    base_dataset=train_dataset_raw,\n",
        "    transform=simclr_transform,\n",
        "    second_transform=simclr_transform\n",
        ")\n",
        "\n",
        "simclr_loader = DataLoader(\n",
        "    simclr_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "simclr_model = SimCLRModel(base_out_dim=128, projection_dim=64).to(device)\n",
        "optimizer_simclr = optim.Adam(simclr_model.parameters(), lr=LR)\n",
        "\n",
        "print(\"SimCLR Warm-Up Training\")\n",
        "for e in range(1, EPOCHS_SIMCLR + 1):\n",
        "    train_simclr_epoch(simclr_model, simclr_loader, optimizer_simclr, epoch=e, temperature=0.5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5674f01d-4f4f-4e35-84f6-90a79229e06e",
      "metadata": {
        "id": "5674f01d-4f4f-4e35-84f6-90a79229e06e"
      },
      "source": [
        "# 5. Triplet Network & Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eddfe1d9-419e-4b52-9e1a-1ea72b838045",
      "metadata": {
        "id": "eddfe1d9-419e-4b52-9e1a-1ea72b838045"
      },
      "outputs": [],
      "source": [
        "class TripletNet(nn.Module):\n",
        "    #Augmenting the existing CNN to use the triplet system\n",
        "    def __init__(self, encoder):\n",
        "        super(TripletNet, self).__init__()\n",
        "        self.encoder = encoder\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        a = self.get_embedding(anchor)\n",
        "        p = self.get_embedding(positive)\n",
        "        n = self.get_embedding(negative)\n",
        "        return a, p, n\n",
        "\n",
        "    def get_embedding(self, x):\n",
        "        #Get raw CNN output\n",
        "        raw_emb = self.encoder(x)\n",
        "        #Normalize to unit sphere\n",
        "        emb = F.normalize(raw_emb, p=2, dim=1)\n",
        "        return emb\n",
        "\n",
        "\n",
        "def build_embedding_cache(model, dataset):\n",
        "    #Store image embeddings rather than constantly recalculating\n",
        "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "    cache_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for (imgs, _) in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            emb_batch = model.get_embedding(imgs).cpu().numpy()\n",
        "            cache_list.append(emb_batch)\n",
        "    return np.concatenate(cache_list, axis=0)\n",
        "\n",
        "\n",
        "class TripletDataset(Dataset):\n",
        "    #If hard_negative is set the system will select a negative which is located nearby\n",
        "    #in order to challenge the network to find more underlying features\n",
        "    def __init__(self, base_dataset, embedding_cache=None, hard_negative=False, K=20):\n",
        "        super().__init__()\n",
        "        self.base_dataset = base_dataset\n",
        "        self.labels = np.array(base_dataset.targets)\n",
        "        self.class_to_indices = {}\n",
        "        for idx, lab in enumerate(self.labels):\n",
        "            if lab not in self.class_to_indices:\n",
        "                self.class_to_indices[lab] = []\n",
        "            self.class_to_indices[lab].append(idx)\n",
        "\n",
        "        self.embedding_cache = embedding_cache\n",
        "        self.hard_negative = hard_negative\n",
        "        self.K = K  # top-K nearest for negatives\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.base_dataset)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        anchor_img, anchor_label = self.base_dataset[index]\n",
        "\n",
        "        #Positive\n",
        "        pos_index = index\n",
        "        while pos_index == index:\n",
        "            pos_index = random.choice(self.class_to_indices[anchor_label])\n",
        "        pos_img, _ = self.base_dataset[pos_index]\n",
        "\n",
        "        #Negative\n",
        "        if not self.hard_negative:\n",
        "            #Random negative from another class\n",
        "            neg_label = anchor_label\n",
        "            while neg_label == anchor_label:\n",
        "                neg_label = random.choice(list(self.class_to_indices.keys()))\n",
        "            neg_index = random.choice(self.class_to_indices[neg_label])\n",
        "        else:\n",
        "            #Semi-hard negative from top-K nearest\n",
        "            anchor_emb = self.embedding_cache[index]\n",
        "            dists = np.sum((self.embedding_cache - anchor_emb)**2, axis=1)\n",
        "            nearest_indices = np.argsort(dists)[1:self.K+1]\n",
        "            candidate_neg = [i_n for i_n in nearest_indices if self.labels[i_n] != anchor_label]\n",
        "            if len(candidate_neg) == 0:\n",
        "                #If hard negative can't be found resort to random\n",
        "                neg_label = anchor_label\n",
        "                while neg_label == anchor_label:\n",
        "                    neg_label = random.choice(list(self.class_to_indices.keys()))\n",
        "                neg_index = random.choice(self.class_to_indices[neg_label])\n",
        "            else:\n",
        "                neg_index = random.choice(candidate_neg)\n",
        "\n",
        "        neg_img, _ = self.base_dataset[neg_index]\n",
        "        return anchor_img, pos_img, neg_img, anchor_label, anchor_label, self.labels[neg_index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "128b514d-3c20-4f23-b3f7-e96f9ed46730",
      "metadata": {
        "id": "128b514d-3c20-4f23-b3f7-e96f9ed46730"
      },
      "source": [
        "# 6. Triplet Training & Distance Checks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c76e3794-db9b-401a-8a5b-d0d580eaca92",
      "metadata": {
        "id": "c76e3794-db9b-401a-8a5b-d0d580eaca92"
      },
      "outputs": [],
      "source": [
        "#Triplet training function\n",
        "def train_one_epoch_triplet(model, loader, optimizer, margin=MARGIN):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for (anchor_img, pos_img, neg_img, _, _, _) in loader:\n",
        "        anchor_img = anchor_img.to(device)\n",
        "        pos_img = pos_img.to(device)\n",
        "        neg_img = neg_img.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        a, p, n = model(anchor_img, pos_img, neg_img)\n",
        "\n",
        "        dist_pos = F.pairwise_distance(a, p, p=2)\n",
        "        dist_neg = F.pairwise_distance(a, n, p=2)\n",
        "        loss = torch.clamp(dist_pos - dist_neg + margin, min=0).mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "#Function to find embedding distances\n",
        "def quick_distance_check(model, dataset, n_pairs=1000):\n",
        "    indices = list(range(len(dataset)))\n",
        "    random.shuffle(indices)\n",
        "    indices = indices[:2000]\n",
        "    loader = DataLoader(Subset(dataset, indices), batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "\n",
        "    emb_list = []\n",
        "    lbl_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            emb = model.get_embedding(imgs).cpu().numpy()\n",
        "            emb_list.append(emb)\n",
        "            lbl_list.append(labels.numpy())\n",
        "\n",
        "    embeddings = np.concatenate(emb_list, axis=0)\n",
        "    all_labels = np.concatenate(lbl_list, axis=0)\n",
        "    n_data = embeddings.shape[0]\n",
        "\n",
        "    same_dists = []\n",
        "    diff_dists = []\n",
        "    for _ in range(n_pairs):\n",
        "        i1, i2 = np.random.randint(0, n_data, size=2)\n",
        "        dist = np.linalg.norm(embeddings[i1] - embeddings[i2])\n",
        "        if all_labels[i1] == all_labels[i2]:\n",
        "            same_dists.append(dist)\n",
        "        else:\n",
        "            diff_dists.append(dist)\n",
        "\n",
        "    if len(same_dists) > 0 and len(diff_dists) > 0:\n",
        "        print(f\"[DistCheck] same={np.mean(same_dists):.4f}, diff={np.mean(diff_dists):.4f}\")\n",
        "    else:\n",
        "        print(\"Not enough pairs to measure.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b27b54af-2bc4-42eb-b511-c49ee257c723",
      "metadata": {
        "id": "b27b54af-2bc4-42eb-b511-c49ee257c723"
      },
      "source": [
        "# 7. Spliced Triplet Training with Hard‐Neg Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecf8ebff-1f9e-4614-96f8-b0357bee3256",
      "metadata": {
        "id": "ecf8ebff-1f9e-4614-96f8-b0357bee3256"
      },
      "outputs": [],
      "source": [
        "triplet_model = TripletNet(simclr_model.encoder).to(device)\n",
        "optimizer_triplet = optim.Adam(triplet_model.parameters(), lr=LR)\n",
        "\n",
        "print(\"Spliced Triplet Training\")\n",
        "current_epoch = 1\n",
        "epochs_left = TOTAL_TRIPLET_EPOCHS\n",
        "\n",
        "while epochs_left > 0:\n",
        "    #Random-negative epochs\n",
        "    for i in range(min(epochs_left, RANDOM_EPOCHS_PER_CYCLE)):\n",
        "        random_dataset = TripletDataset(\n",
        "            base_dataset=train_dataset_raw,\n",
        "            embedding_cache=None,\n",
        "            hard_negative=False\n",
        "        )\n",
        "        random_loader = DataLoader(\n",
        "            random_dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            pin_memory=True\n",
        "        )\n",
        "        loss_r = train_one_epoch_triplet(triplet_model, random_loader, optimizer_triplet, margin=MARGIN)\n",
        "        print(f\"[Epoch {current_epoch}] RandomNeg Loss={loss_r:.4f}\")\n",
        "        quick_distance_check(triplet_model, train_dataset_raw)\n",
        "\n",
        "        current_epoch += 1\n",
        "        epochs_left -= 1\n",
        "        if epochs_left <= 0:\n",
        "            break\n",
        "\n",
        "    if epochs_left <= 0:\n",
        "        break\n",
        "\n",
        "    #Hard-negative (semi-hard) epoch\n",
        "    embed_cache = build_embedding_cache(triplet_model, train_dataset_raw)\n",
        "    hard_dataset = TripletDataset(\n",
        "        base_dataset=train_dataset_raw,\n",
        "        embedding_cache=embed_cache,\n",
        "        hard_negative=True,\n",
        "        K=20  #pick from top-20 nearest\n",
        "    )\n",
        "    hard_loader = DataLoader(\n",
        "        hard_dataset,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=True,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    loss_h = train_one_epoch_triplet(triplet_model, hard_loader, optimizer_triplet, margin=MARGIN)\n",
        "    print(f\"[Epoch {current_epoch}] HardNeg Loss={loss_h:.4f}\")\n",
        "    quick_distance_check(triplet_model, train_dataset_raw)\n",
        "\n",
        "    current_epoch += 1\n",
        "    epochs_left -= 1\n",
        "\n",
        "print(\"Finished Spliced Triplet Training\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bcd95163-a0db-4098-a9b8-76fdaca39ac2",
      "metadata": {
        "id": "bcd95163-a0db-4098-a9b8-76fdaca39ac2"
      },
      "source": [
        "# **Save & Load Code Block**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b6c0871-79f6-43a6-99bd-c3b73fc64b11",
      "metadata": {
        "id": "0b6c0871-79f6-43a6-99bd-c3b73fc64b11"
      },
      "outputs": [],
      "source": [
        "def save_triplet_model(model, optimizer, epoch, filepath=\"triplet_model_checkpoint.pth\"):\n",
        "    \"\"\"\n",
        "    model: TripletNet instance\n",
        "    optimizer: optimizer_triplet\n",
        "    epoch: current epoch or training step\n",
        "    filepath: where to save\n",
        "    \"\"\"\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state': model.state_dict(),\n",
        "        'optimizer_state': optimizer.state_dict()\n",
        "    }, filepath)\n",
        "    print(f\"Model saved to {filepath}\")\n",
        "\n",
        "def load_triplet_model(model, optimizer, filepath=\"triplet_model_checkpoint.pth\"):\n",
        "    \"\"\"\n",
        "    Load states into 'model' and 'optimizer'.\n",
        "    \"\"\"\n",
        "    checkpoint = torch.load(filepath, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
        "    start_epoch = checkpoint['epoch'] + 1\n",
        "    print(f\"Model loaded from {filepath}, resume from epoch {start_epoch}\")\n",
        "    return start_epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76c5e61a-1c85-404f-bfcb-1e0ae49c929b",
      "metadata": {
        "id": "76c5e61a-1c85-404f-bfcb-1e0ae49c929b"
      },
      "outputs": [],
      "source": [
        "# === Save the model ===\n",
        "save_triplet_model(triplet_model, optimizer_triplet, current_epoch, \"triplet_model_checkpoint.pth\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35d4d70-6145-4cbb-bfa2-1d04dc19b55c",
      "metadata": {
        "id": "f35d4d70-6145-4cbb-bfa2-1d04dc19b55c"
      },
      "outputs": [],
      "source": [
        "# === Load the model ===\n",
        "resume_epoch = load_triplet_model(triplet_model, optimizer_triplet, \"triplet_model_checkpoint.pth\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2691296-5399-408d-aae0-cc9763f6e8e6",
      "metadata": {
        "id": "a2691296-5399-408d-aae0-cc9763f6e8e6"
      },
      "source": [
        "# 8. Data Visualization & Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a1817d6-8cf6-4be0-83ec-1cdfa9e7b8d5",
      "metadata": {
        "id": "0a1817d6-8cf6-4be0-83ec-1cdfa9e7b8d5"
      },
      "outputs": [],
      "source": [
        "def embedding_visuals(model, dataset, max_images=2000):\n",
        "    \"\"\"\n",
        "    Generates PCA, UMAP, and t-SNE visualizations on a subset of 'dataset'.\n",
        "    Colored according to ground-truth labels for reference.\n",
        "    \"\"\"\n",
        "\n",
        "    indices = list(range(len(dataset)))\n",
        "    random.shuffle(indices)\n",
        "    indices = indices[:max_images]\n",
        "\n",
        "    sub_loader = DataLoader(\n",
        "        Subset(dataset, indices),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    emb_list = []\n",
        "    lbl_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in sub_loader:\n",
        "            imgs = imgs.to(device)\n",
        "            emb_batch = model.get_embedding(imgs).cpu().numpy()\n",
        "            emb_list.append(emb_batch)\n",
        "            lbl_list.append(labels.numpy())\n",
        "\n",
        "    embeddings = np.concatenate(emb_list, axis=0)\n",
        "    labels_np = np.concatenate(lbl_list, axis=0)\n",
        "\n",
        "    #Principal Component Analysis\n",
        "    #Finds directionality in data with the greatest variance\n",
        "    #Simplified; it \"kinda\" maps features to a directional vector and each feature pushes\n",
        "    #a data point in a direction\n",
        "    pca = PCA(n_components=2, random_state=42)\n",
        "    emb_pca = pca.fit_transform(embeddings)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(emb_pca[:,0], emb_pca[:,1], c=labels_np, cmap='tab20', s=5)\n",
        "    plt.title(\"PCA (final embeddings, subset)\")\n",
        "    plt.show()\n",
        "\n",
        "    #Uniform Manifold Approximation and Projection\n",
        "    #Maps data based on how likely or unlikely each point is to be close to\n",
        "    #each other then maps this fuzzy distance understanding to 2d space\n",
        "    reducer = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.1, random_state=42)\n",
        "    emb_umap = reducer.fit_transform(embeddings)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(emb_umap[:,0], emb_umap[:,1], c=labels_np, cmap='tab20', s=5)\n",
        "    plt.title(\"UMAP (final embeddings, subset)\")\n",
        "    plt.show()\n",
        "\n",
        "    #t-Distributed Stochastic Neighbor Embeddings\n",
        "    #Creates \"neighborhoods\" to find groups of data that would be close to one another\n",
        "    #Then uses this fuzzy understanding to group data together\n",
        "    tsne_model = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "    emb_tsne = tsne_model.fit_transform(embeddings)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(emb_tsne[:,0], emb_tsne[:,1], c=labels_np, cmap='tab20', s=5)\n",
        "    plt.title(\"t-SNE (final embeddings, subset)\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def cluster_test_set_hdbscan(model, dataset, max_images=2000):\n",
        "    #Clusters dataset with HBDSCAN\n",
        "    #Prints ARI and NMI for debuging purposes\n",
        "\n",
        "    indices = list(range(len(dataset)))\n",
        "    random.shuffle(indices)\n",
        "    indices = indices[:max_images]\n",
        "\n",
        "    loader = DataLoader(\n",
        "        Subset(dataset, indices),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        shuffle=False,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    emb_list = []\n",
        "    lbl_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for imgs, lbls in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            emb = model.get_embedding(imgs).cpu().numpy()\n",
        "            emb_list.append(emb)\n",
        "            lbl_list.append(lbls.numpy())\n",
        "\n",
        "    embeddings = np.concatenate(emb_list, axis=0)\n",
        "    labels_np = np.concatenate(lbl_list, axis=0)\n",
        "\n",
        "    clusterer = hdbscan.HDBSCAN(min_cluster_size=30)\n",
        "    preds = clusterer.fit_predict(embeddings)\n",
        "\n",
        "    n_clusters = len(set(preds) - {-1})\n",
        "    print(f\"[HDBSCAN] Found {n_clusters} clusters (excluding noise label=-1).\")\n",
        "\n",
        "    valid_idx = preds != -1\n",
        "    if np.sum(valid_idx) > 0:\n",
        "        ari = adjusted_rand_score(labels_np[valid_idx], preds[valid_idx])\n",
        "        nmi = normalized_mutual_info_score(labels_np[valid_idx], preds[valid_idx])\n",
        "        print(f\" ARI={ari:.4f}, NMI={nmi:.4f}\")\n",
        "    else:\n",
        "        print(\" No valid (non-noise) clusters for ARI/NMI.\")\n",
        "\n",
        "    #UMAP scatter for cluster visualization\n",
        "    reducer = umap.UMAP(n_neighbors=15, n_components=2, min_dist=0.5, random_state=42)\n",
        "    emb_umap = reducer.fit_transform(embeddings)\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.scatter(emb_umap[:,0], emb_umap[:,1], c=preds, cmap='Spectral', s=5)\n",
        "    plt.title(\"UMAP of Test Embeddings colored by HDBSCAN clusters\")\n",
        "    plt.show()\n",
        "\n",
        "embedding_visuals(triplet_model, test_dataset_raw, max_images=2000)\n",
        "cluster_test_set_hdbscan(triplet_model, test_dataset_raw, max_images=2000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "caaa7cf5-b413-4801-86e2-18dcb3572786",
      "metadata": {
        "id": "caaa7cf5-b413-4801-86e2-18dcb3572786"
      },
      "source": [
        "# 9. Select & Cluster Initial Subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52e58b27-7e9d-40c5-9b13-42a0fb4dea59",
      "metadata": {
        "id": "52e58b27-7e9d-40c5-9b13-42a0fb4dea59"
      },
      "outputs": [],
      "source": [
        "class UnlabeledSubset(Dataset):\n",
        "    #Limits the amount of classes that can be used in the dataset\n",
        "    def __init__(self, base_dataset, max_images=5000, max_classes=10):\n",
        "        self.base_dataset = base_dataset\n",
        "        labels_array = np.array(base_dataset.targets)\n",
        "        unique_labels = np.unique(labels_array)\n",
        "        random.shuffle(unique_labels)\n",
        "        chosen_labels = unique_labels[:max_classes]\n",
        "\n",
        "        indices = []\n",
        "        for cl in chosen_labels:\n",
        "            these_idx = np.where(labels_array == cl)[0]\n",
        "            indices.extend(these_idx.tolist())\n",
        "        random.shuffle(indices)\n",
        "        indices = indices[:max_images]\n",
        "        self.indices = indices\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        real_idx = self.indices[idx]\n",
        "        img, lbl = self.base_dataset[real_idx]\n",
        "        return img, lbl\n",
        "\n",
        "print(\"Selecting subset images from limited classes\")\n",
        "\n",
        "#Replace 'train_dataset_raw' with base dataset\n",
        "unlabeled_init_dataset = UnlabeledSubset(train_dataset_raw, max_images=5000, max_classes=10)\n",
        "print(f\"  => Subset size: {len(unlabeled_init_dataset)} images\")\n",
        "\n",
        "#Build embeddings for subset\n",
        "loader_init = DataLoader(unlabeled_init_dataset, batch_size=BATCH_SIZE, shuffle=False, pin_memory=True)\n",
        "init_emb_list = []\n",
        "init_labels_list = []\n",
        "triplet_model.eval()\n",
        "with torch.no_grad():\n",
        "    for imgs, lbls in loader_init:\n",
        "        imgs = imgs.to(device)\n",
        "        emb_batch = triplet_model.get_embedding(imgs).cpu().numpy()\n",
        "        init_emb_list.append(emb_batch)\n",
        "        init_labels_list.extend(lbls.numpy())\n",
        "\n",
        "init_embeddings = np.concatenate(init_emb_list, axis=0)\n",
        "init_labels = np.array(init_labels_list)\n",
        "\n",
        "clusterer_init = hdbscan.HDBSCAN(min_cluster_size=50)\n",
        "init_preds = clusterer_init.fit_predict(init_embeddings)\n",
        "unique_clusters_init = set(init_preds) - {-1}\n",
        "\n",
        "cluster_buckets = {}\n",
        "for cid in unique_clusters_init:\n",
        "    cluster_buckets[cid] = []\n",
        "cluster_buckets['noise'] = []\n",
        "\n",
        "for i, c in enumerate(init_preds):\n",
        "    if c == -1:\n",
        "        cluster_buckets['noise'].append(i)\n",
        "    else:\n",
        "        cluster_buckets[c].append(i)\n",
        "\n",
        "print(\"Initial Clusters\")\n",
        "for k in cluster_buckets:\n",
        "    print(f\"  Cluster {k}: size={len(cluster_buckets[k])}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1755f4d-c1ea-4325-bbe0-31a33793669e",
      "metadata": {
        "id": "f1755f4d-c1ea-4325-bbe0-31a33793669e"
      },
      "source": [
        "# 10. StreamingClusterManager + GravityTripletDataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72f8078c-a4c4-4361-b44d-3d163d8ea2d7",
      "metadata": {
        "id": "72f8078c-a4c4-4361-b44d-3d163d8ea2d7"
      },
      "outputs": [],
      "source": [
        "#Class for triplet-trained dataset\n",
        "class GravityTripletDataset(Dataset):\n",
        "    def __init__(self, model, device, all_embeddings, base_dataset, triplets_info):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.all_embeddings = all_embeddings\n",
        "        self.base_dataset = base_dataset\n",
        "        self.triplets_info = triplets_info\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.triplets_info)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        idx_img, pos_centroid, neg_centroid = self.triplets_info[idx]\n",
        "        img, _ = self.base_dataset[idx_img]\n",
        "        return (\n",
        "            img,\n",
        "            torch.tensor(pos_centroid, dtype=torch.float32),\n",
        "            torch.tensor(neg_centroid, dtype=torch.float32),\n",
        "        )\n",
        "\n",
        "#Class for streaming images into existing clusters\n",
        "class StreamingClusterManager:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model,\n",
        "        device,\n",
        "        init_embeddings,\n",
        "        init_preds,\n",
        "        init_labels,\n",
        "        cluster_buckets,\n",
        "        distance_threshold=1.5\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.distance_threshold = distance_threshold\n",
        "        self.all_embeddings = init_embeddings.copy()\n",
        "        self.all_cluster_ids = init_preds.copy()\n",
        "        self.all_labels = init_labels.copy()\n",
        "        self.num_initial = self.all_embeddings.shape[0]\n",
        "\n",
        "        self.cluster_buckets = {}\n",
        "        for cid in cluster_buckets:\n",
        "            self.cluster_buckets[cid] = []\n",
        "        for cid in cluster_buckets:\n",
        "            for idx_val in cluster_buckets[cid]:\n",
        "                if idx_val < self.num_initial:\n",
        "                    self.cluster_buckets[cid].append(idx_val)\n",
        "\n",
        "        self.centroids = {}\n",
        "        for cid in self.cluster_buckets:\n",
        "            if len(self.cluster_buckets[cid]) > 0:\n",
        "                emb_sub = self.all_embeddings[self.cluster_buckets[cid]]\n",
        "                centroid = emb_sub.mean(axis=0)\n",
        "                self.centroids[cid] = centroid\n",
        "\n",
        "    #Assign image based on embedding distance\n",
        "    def assign_new_image(self, img_tensor, true_label):\n",
        "        if img_tensor.ndim == 3:\n",
        "            img_tensor = img_tensor.unsqueeze(0)\n",
        "        img_tensor = img_tensor.to(self.device)\n",
        "        with torch.no_grad():\n",
        "            emb = self.model.get_embedding(img_tensor).cpu().numpy()[0]\n",
        "\n",
        "        if len(self.centroids) == 0:\n",
        "            new_cid = 0\n",
        "            self.cluster_buckets[new_cid] = [self.num_initial]\n",
        "            self.all_cluster_ids = np.append(self.all_cluster_ids, new_cid)\n",
        "            self.all_embeddings = np.vstack([self.all_embeddings, emb])\n",
        "            self.all_labels = np.append(self.all_labels, true_label)\n",
        "            self.centroids[new_cid] = emb\n",
        "            self.num_initial += 1\n",
        "            return (new_cid, 0.0)\n",
        "\n",
        "        dists = {}\n",
        "        for cid, cvec in self.centroids.items():\n",
        "            dists[cid] = np.linalg.norm(emb - cvec)\n",
        "        nearest_cid = min(dists, key=dists.get)\n",
        "        nearest_dist = dists[nearest_cid]\n",
        "\n",
        "        if nearest_dist > self.distance_threshold:\n",
        "            new_cid = max([x for x in self.centroids.keys() if isinstance(x, int)], default=-1) + 1\n",
        "            self.cluster_buckets[new_cid] = [self.num_initial]\n",
        "            self.all_cluster_ids = np.append(self.all_cluster_ids, new_cid)\n",
        "            self.all_embeddings = np.vstack([self.all_embeddings, emb])\n",
        "            self.all_labels = np.append(self.all_labels, true_label)\n",
        "            self.centroids[new_cid] = emb\n",
        "            self.num_initial += 1\n",
        "            return (new_cid, 0.0)\n",
        "        else:\n",
        "            idx_new = self.num_initial\n",
        "            self.num_initial += 1\n",
        "            self.all_cluster_ids = np.append(self.all_cluster_ids, nearest_cid)\n",
        "            self.all_embeddings = np.vstack([self.all_embeddings, emb])\n",
        "            self.all_labels = np.append(self.all_labels, true_label)\n",
        "            self.cluster_buckets[nearest_cid].append(idx_new)\n",
        "\n",
        "            old_count = len(self.cluster_buckets[nearest_cid]) - 1\n",
        "            old_centroid = self.centroids[nearest_cid]\n",
        "            new_count = old_count + 1\n",
        "            new_centroid = (old_centroid * old_count + emb) / new_count\n",
        "            self.centroids[nearest_cid] = new_centroid\n",
        "            return (nearest_cid, nearest_dist)\n",
        "\n",
        "    def periodic_recluster(self):\n",
        "        if self.all_embeddings.shape[0] == 0:\n",
        "            return\n",
        "        clusterer = hdbscan.HDBSCAN(min_cluster_size=50)\n",
        "        new_preds = clusterer.fit_predict(self.all_embeddings)\n",
        "        #Possibly reassign or merge clusters here if desired.\n",
        "\n",
        "    #Gravity retraining; \"pulls\" data closer to its cluster center\n",
        "    def gravity_retrain(\n",
        "        self,\n",
        "        optimizer,\n",
        "        unlabeled_dataset,\n",
        "        margin=1.0,\n",
        "        epochs=3,\n",
        "        outlier_cid=\"noise\"\n",
        "    ):\n",
        "        all_triplets = []\n",
        "        cluster_ids_list = sorted([c for c in self.cluster_buckets.keys() if isinstance(c, int)])\n",
        "        if outlier_cid in self.cluster_buckets:\n",
        "            cluster_ids_list.append(outlier_cid)\n",
        "\n",
        "        for cid in cluster_ids_list:\n",
        "            if cid not in self.cluster_buckets:\n",
        "                continue\n",
        "            indices_c = self.cluster_buckets[cid]\n",
        "            if len(indices_c) < 10:\n",
        "                continue\n",
        "            random.shuffle(indices_c)\n",
        "            sample_indices = indices_c[:50]\n",
        "            other_cids = [x for x in cluster_ids_list if x != cid and x in self.cluster_buckets]\n",
        "            if len(other_cids) == 0:\n",
        "                continue\n",
        "            neg_cid = random.choice(other_cids)\n",
        "            if neg_cid not in self.centroids:\n",
        "                continue\n",
        "            if cid not in self.centroids:\n",
        "                continue\n",
        "            neg_centroid = self.centroids[neg_cid]\n",
        "            pos_centroid = self.centroids[cid]\n",
        "            for idx_img in sample_indices:\n",
        "                all_triplets.append((idx_img, pos_centroid, neg_centroid))\n",
        "\n",
        "        ds = GravityTripletDataset(\n",
        "            self.model,\n",
        "            self.device,\n",
        "            self.all_embeddings,\n",
        "            unlabeled_dataset,\n",
        "            all_triplets\n",
        "        )\n",
        "        if len(ds) == 0:\n",
        "            return\n",
        "        loader = DataLoader(ds, batch_size=32, shuffle=True, pin_memory=True)\n",
        "        for _ in range(epochs):\n",
        "            self.model.train()\n",
        "            for anchor_img, pos_vec, neg_vec in loader:\n",
        "                anchor_img = anchor_img.to(self.device)\n",
        "                optimizer.zero_grad()\n",
        "                a_emb = self.model.get_embedding(anchor_img)\n",
        "                pos_vec = pos_vec.to(self.device)\n",
        "                neg_vec = neg_vec.to(self.device)\n",
        "                dist_pos = F.pairwise_distance(a_emb, pos_vec, p=2)\n",
        "                dist_neg = F.pairwise_distance(a_emb, neg_vec, p=2)\n",
        "                loss = torch.clamp(dist_pos - dist_neg + margin, min=0).mean()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "    #Function for iteratively adding images to the clusters\n",
        "    def iterative_streaming_cycle(\n",
        "        self,\n",
        "        new_dataset,\n",
        "        optimizer,\n",
        "        unlabeled_dataset,\n",
        "        cycle_size=1000,\n",
        "        total_images=5000,\n",
        "        margin=1.0,\n",
        "        retrain_epochs=3,\n",
        "        outlier_cid=\"noise\"\n",
        "    ):\n",
        "        images_streamed = 0\n",
        "        while images_streamed < total_images:\n",
        "            batch_end = min(images_streamed + cycle_size, total_images)\n",
        "            for i in range(images_streamed, batch_end):\n",
        "                if i >= len(new_dataset):\n",
        "                    break\n",
        "                img_tensor, lbl = new_dataset[i]\n",
        "                self.assign_new_image(img_tensor, lbl)\n",
        "            images_streamed = batch_end\n",
        "            self.gravity_retrain(\n",
        "                optimizer=optimizer,\n",
        "                unlabeled_dataset=unlabeled_dataset,\n",
        "                margin=margin,\n",
        "                epochs=retrain_epochs,\n",
        "                outlier_cid=outlier_cid\n",
        "            )\n",
        "\n",
        "    #Metrics for showing accuracy of clusters\n",
        "    def compute_metrics(self):\n",
        "        valid_mask = [i for i in range(len(self.all_cluster_ids)) if self.all_cluster_ids[i] != -1]\n",
        "        assigned_clusters = self.all_cluster_ids[valid_mask]\n",
        "        assigned_labels = self.all_labels[valid_mask]\n",
        "        if len(set(assigned_clusters)) <= 1:\n",
        "            return\n",
        "        ari_val = adjusted_rand_score(assigned_labels, assigned_clusters)\n",
        "        nmi_val = normalized_mutual_info_score(assigned_labels, assigned_clusters)\n",
        "        print(f\"ARI={ari_val:.4f}, NMI={nmi_val:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2816d5a-6f67-421a-a6fa-805dde630384",
      "metadata": {
        "id": "c2816d5a-6f67-421a-a6fa-805dde630384"
      },
      "source": [
        "# 11. Visualization, Loop & Summaries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1f07a7-79a8-45ae-8d44-66a5219ad223",
      "metadata": {
        "id": "3c1f07a7-79a8-45ae-8d44-66a5219ad223"
      },
      "outputs": [],
      "source": [
        "def plot_clusters(manager, max_points=2000):\n",
        "    if manager.all_embeddings.shape[0] == 0:\n",
        "        return\n",
        "    if manager.all_embeddings.shape[0] > max_points:\n",
        "        idx_subset = np.random.choice(manager.all_embeddings.shape[0], max_points, replace=False)\n",
        "        emb_subset = manager.all_embeddings[idx_subset]\n",
        "        clust_subset = manager.all_cluster_ids[idx_subset]\n",
        "    else:\n",
        "        emb_subset = manager.all_embeddings\n",
        "        clust_subset = manager.all_cluster_ids\n",
        "\n",
        "    #Convert outliers to -1 cluster to standardize to int\n",
        "    clust_subset_str = clust_subset.astype(str)\n",
        "    clust_subset_str[clust_subset_str == 'noise'] = '-1'\n",
        "    clust_subset_str[clust_subset_str == '-1'] = '-1'\n",
        "    clust_subset_int = clust_subset_str.astype(int)\n",
        "\n",
        "    tsne_model = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "    emb_tsne = tsne_model.fit_transform(emb_subset)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(emb_tsne[:, 0], emb_tsne[:, 1], c=clust_subset_int, cmap='tab20', s=5)\n",
        "    plt.title(\"t-SNE Clusters\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_cluster_counts(manager):\n",
        "    #Include np.integer to account for NumPy int64 keys\n",
        "    cluster_ids_sorted = sorted(\n",
        "        c for c in manager.cluster_buckets.keys()\n",
        "        if isinstance(c, (int, np.integer))\n",
        "    )\n",
        "    cluster_sizes = [len(manager.cluster_buckets[c]) for c in cluster_ids_sorted]\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.bar([str(k) for k in cluster_ids_sorted], cluster_sizes, color='skyblue')\n",
        "    plt.xlabel(\"Cluster ID\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.title(\"Cluster Counts\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def print_ari_nmi(manager):\n",
        "    valid_mask = [i for i in range(len(manager.all_cluster_ids)) if manager.all_cluster_ids[i] != -1]\n",
        "    assigned_clusters = manager.all_cluster_ids[valid_mask]\n",
        "    assigned_labels = manager.all_labels[valid_mask]\n",
        "\n",
        "    if len(set(assigned_clusters)) <= 1:\n",
        "        return\n",
        "\n",
        "    ari_val = adjusted_rand_score(assigned_labels, assigned_clusters)\n",
        "    nmi_val = normalized_mutual_info_score(assigned_labels, assigned_clusters)\n",
        "    print(f\"ARI={ari_val:.4f}, NMI={nmi_val:.4f}\")\n",
        "\n",
        "\n",
        "def final_summary(manager):\n",
        "    cluster_ids_sorted = sorted(\n",
        "        c for c in manager.cluster_buckets.keys()\n",
        "        if isinstance(c, (int, np.integer))\n",
        "    )\n",
        "\n",
        "    print(\"\\nFinal Cluster Sizes:\")\n",
        "    for cid in cluster_ids_sorted:\n",
        "        print(f\"  Cluster {cid} -> {len(manager.cluster_buckets[cid])} items\")\n",
        "\n",
        "    print(f\"\\nNumber of clusters (excluding 'noise'): {len(cluster_ids_sorted)}\")\n",
        "\n",
        "    #Simple \"dominant label\" approach for each cluster\n",
        "    #Limits definition of accuracy in whats supposed to be\n",
        "    #a general clustering round\n",
        "    print(\"\\nDominant Label (old single-label purity measure):\")\n",
        "    for cid in cluster_ids_sorted:\n",
        "        indices_c = manager.cluster_buckets[cid]\n",
        "        labels_c = manager.all_labels[indices_c]\n",
        "        label_counts = Counter(labels_c)\n",
        "        if len(indices_c) == 0:\n",
        "            print(f\"  Cluster {cid}: 0 items.\")\n",
        "            continue\n",
        "        domin_label, dom_count = label_counts.most_common(1)[0]\n",
        "        purity = dom_count / len(indices_c)\n",
        "        print(f\"  Cluster {cid}: domin_label={domin_label}, purity={purity:.4f}\")\n",
        "\n",
        "    #ARI / NMI on all assigned data\n",
        "    valid_mask = [i for i in range(len(manager.all_cluster_ids)) if manager.all_cluster_ids[i] != -1]\n",
        "    assigned_clusters = manager.all_cluster_ids[valid_mask]\n",
        "    assigned_labels = manager.all_labels[valid_mask]\n",
        "    if len(set(assigned_clusters)) <= 1:\n",
        "        print(\"\\nFinal ARI/NMI not computed (only one cluster).\")\n",
        "    else:\n",
        "        ari_val = adjusted_rand_score(assigned_labels, assigned_clusters)\n",
        "        nmi_val = normalized_mutual_info_score(assigned_labels, assigned_clusters)\n",
        "        print(f\"\\nFinal ARI={ari_val:.4f}, NMI={nmi_val:.4f}\")\n",
        "\n",
        "    #Multi-label Purity for Each Cluster\n",
        "    #For each cluster, list each label contained and the fraction\n",
        "    #of the cluster that label occupies. Summarize them as well.\n",
        "    print(\"\\nMulti-label Breakdown for Each Cluster:\")\n",
        "    for cid in cluster_ids_sorted:\n",
        "        indices_c = manager.cluster_buckets[cid]\n",
        "        if not indices_c:\n",
        "            print(f\"  Cluster {cid}: 0 items.\")\n",
        "            continue\n",
        "        labels_c = manager.all_labels[indices_c]\n",
        "        label_counts = Counter(labels_c)\n",
        "        cluster_size = len(indices_c)\n",
        "\n",
        "        print(f\"  Cluster {cid} (size={cluster_size}):\")\n",
        "        #Sort labels in descending order of count\n",
        "        for lbl_val, lbl_count in label_counts.most_common():\n",
        "            frac = lbl_count / cluster_size\n",
        "            print(f\"    label={lbl_val} => count={lbl_count}, fraction={frac:.4f}\")\n",
        "\n",
        "\n",
        "def long_loop_streaming(manager,\n",
        "                        new_dataset,\n",
        "                        optimizer,\n",
        "                        unlabeled_dataset,\n",
        "                        total_cycles=50,\n",
        "                        images_per_cycle=200,\n",
        "                        margin=1.0,\n",
        "                        retrain_epochs=3,\n",
        "                        outlier_cid=\"noise\"):\n",
        "    images_streamed = 0\n",
        "    for cycle in range(1, total_cycles + 1):\n",
        "        start_idx = images_streamed\n",
        "        end_idx = images_streamed + images_per_cycle\n",
        "        for i in range(start_idx, end_idx):\n",
        "            if i >= len(new_dataset):\n",
        "                break\n",
        "            img_tensor, lbl = new_dataset[i]\n",
        "            manager.assign_new_image(img_tensor, lbl)\n",
        "\n",
        "        images_streamed = end_idx\n",
        "        manager.gravity_retrain(\n",
        "            optimizer=optimizer,\n",
        "            unlabeled_dataset=unlabeled_dataset,\n",
        "            margin=margin,\n",
        "            epochs=retrain_epochs,\n",
        "            outlier_cid=outlier_cid\n",
        "        )\n",
        "\n",
        "        print(f\"\\nCycle {cycle}/{total_cycles} complete. Images streamed so far: {images_streamed}.\")\n",
        "        manager.compute_metrics()\n",
        "        plot_clusters(manager)\n",
        "        plot_cluster_counts(manager)\n",
        "        print_ari_nmi(manager)\n",
        "\n",
        "        if images_streamed >= len(new_dataset):\n",
        "            break\n",
        "\n",
        "    print(\"\\nAll cycles complete.\")\n",
        "    print(\"DEBUG: manager.cluster_buckets keys & sizes:\")\n",
        "    for k in manager.cluster_buckets:\n",
        "        print(f\"  {k} -> {len(manager.cluster_buckets[k])} items\")\n",
        "\n",
        "    for k in manager.cluster_buckets:\n",
        "        print(f\"  {k} -> {len(manager.cluster_buckets[k])} items  (type={type(k)})\")\n",
        "\n",
        "    final_summary(manager)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcfeb11b-0c9e-493b-a39e-a29c6455e110",
      "metadata": {
        "id": "bcfeb11b-0c9e-493b-a39e-a29c6455e110"
      },
      "outputs": [],
      "source": [
        "#Using the results of Block 9\n",
        "#init_embeddings, init_preds, init_labels, cluster_buckets\n",
        "\n",
        "manager = StreamingClusterManager(\n",
        "    model=triplet_model,\n",
        "    device=device,\n",
        "    init_embeddings=init_embeddings,\n",
        "    init_preds=init_preds,\n",
        "    init_labels=init_labels,\n",
        "    cluster_buckets=cluster_buckets,\n",
        "    distance_threshold=0.5\n",
        ")\n",
        "\n",
        "new_dataset = test_dataset_raw\n",
        "\n",
        "long_loop_streaming(\n",
        "    manager=manager,\n",
        "    new_dataset=new_dataset,\n",
        "    optimizer=optimizer_triplet,\n",
        "    unlabeled_dataset=unlabeled_init_dataset,\n",
        "    total_cycles=50,\n",
        "    images_per_cycle=200,\n",
        "    margin=1.0,\n",
        "    retrain_epochs=3,\n",
        "    outlier_cid=\"noise\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12. Evaluate & plot class assignment accuracy"
      ],
      "metadata": {
        "id": "wL11c50nPH4w"
      },
      "id": "wL11c50nPH4w"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c753919-686f-4f9a-9fec-26b129e9d9bd",
      "metadata": {
        "id": "3c753919-686f-4f9a-9fec-26b129e9d9bd"
      },
      "outputs": [],
      "source": [
        "def evaluate_class_accuracy(manager):\n",
        "\n",
        "    #'manager.all_cluster_ids' has a cluster ID (or -1 for noise) for each image index.\n",
        "    #'manager.all_labels' has the corresponding true label for each image index.\n",
        "    cluster_ids = manager.all_cluster_ids\n",
        "    labels = manager.all_labels\n",
        "\n",
        "    #Filter out noise indices if you want to skip them in the analysis\n",
        "    valid_indices = np.where(cluster_ids != -1)[0]\n",
        "    valid_clusters = cluster_ids[valid_indices]\n",
        "    valid_labels   = labels[valid_indices]\n",
        "\n",
        "    #Build a dictionary: (cluster -> Counter of labels)\n",
        "    cluster_label_counts = defaultdict(Counter)\n",
        "    for i, c in zip(valid_indices, valid_clusters):\n",
        "        lbl = labels[i]\n",
        "        cluster_label_counts[c][lbl] += 1\n",
        "\n",
        "    #Build a total label count\n",
        "    total_label_count = Counter(valid_labels)\n",
        "\n",
        "    #1) For each label L, find the cluster that has the maximum count of L.\n",
        "    best_cluster_for_label = {}\n",
        "    unique_labels = sorted(set(valid_labels))\n",
        "    cluster_ids_sorted = sorted(\n",
        "        c for c in set(valid_clusters) if c != -1\n",
        "    )\n",
        "\n",
        "    for L in unique_labels:\n",
        "        best_cid = None\n",
        "        best_count = 0\n",
        "        for cid in cluster_ids_sorted:\n",
        "            c_count = cluster_label_counts[cid][L]\n",
        "            if c_count > best_count:\n",
        "                best_count = c_count\n",
        "                best_cid = cid\n",
        "        best_cluster_for_label[L] = (best_cid, best_count)\n",
        "\n",
        "    #2) Compute per-label accuracy = (# L in best cluster) / (total # L)\n",
        "    print(\"\\nPer-Label Accuracy (Using Largest-Count Cluster):\")\n",
        "    label_accuracies = {}\n",
        "    overall_correct = 0\n",
        "    overall_total   = 0\n",
        "    for L in unique_labels:\n",
        "        best_cid, best_count_for_L = best_cluster_for_label[L]\n",
        "        total_L = total_label_count[L]\n",
        "        if total_L > 0:\n",
        "            acc_L = best_count_for_L / total_L\n",
        "        else:\n",
        "            acc_L = 0.0\n",
        "        label_accuracies[L] = acc_L\n",
        "        overall_correct += best_count_for_L\n",
        "        overall_total   += total_L\n",
        "        print(f\"  Label {L}: best_cluster={best_cid}, correct={best_count_for_L}, total={total_L}, acc={acc_L:.4f}\")\n",
        "\n",
        "    overall_system_acc = overall_correct / overall_total if overall_total else 0.0\n",
        "    print(f\"\\nOverall System Accuracy (summing per-label correct / total) = {overall_system_acc:.4f}\")\n",
        "\n",
        "    #3) Count \"errors\" per cluster: i.e., images in each cluster that do NOT belong\n",
        "    #   to that cluster for their label's best cluster.\n",
        "    print(\"\\nPer-Cluster Error Counts:\")\n",
        "    cluster_error = {}\n",
        "    for cid in cluster_ids_sorted:\n",
        "        cluster_error[cid] = 0\n",
        "\n",
        "    #Map label -> correct cluster\n",
        "    correct_cluster_for_label = {}\n",
        "    for L, (cid, _) in best_cluster_for_label.items():\n",
        "        correct_cluster_for_label[L] = cid\n",
        "\n",
        "    #Go through each valid index again, see if label's correct cluster matches\n",
        "    for i in valid_indices:\n",
        "        c = cluster_ids[i]\n",
        "        lbl = labels[i]\n",
        "        #If this cluster c is not the correct cluster for label lbl => error\n",
        "        if c != correct_cluster_for_label[lbl]:\n",
        "            cluster_error[c] += 1\n",
        "\n",
        "    for cid in cluster_ids_sorted:\n",
        "        size_c = len(manager.cluster_buckets[cid])\n",
        "        err_c  = cluster_error[cid]\n",
        "        print(f\"  Cluster {cid}: size={size_c}, errors={err_c}, error_rate={err_c/size_c if size_c>0 else 0:.4f}\")\n",
        "\n",
        "    print(\"\\nDone evaluating class accuracy.\\n\")\n",
        "\n",
        "def plot_class_accuracy(manager):\n",
        "    \"\"\"\n",
        "    Plots a bar chart of per-label accuracy using the \"largest-cluster\" approach.\n",
        "    For each label L, we find the cluster that contains the most of L, and treat\n",
        "    all L in that cluster as \"correct.\" Then we compute accuracy = correct / total(L).\n",
        "\n",
        "    NOTE: This function re-computes the label-cluster assignments internally, so\n",
        "    you don't need to call evaluate_class_accuracy beforehand.\n",
        "    \"\"\"\n",
        "\n",
        "    #Gather assigned (non-noise) indices\n",
        "    cluster_ids = manager.all_cluster_ids\n",
        "    labels      = manager.all_labels\n",
        "    valid_indices = np.where(cluster_ids != -1)[0]\n",
        "    if len(valid_indices) == 0:\n",
        "        print(\"No non-noise assignments to evaluate.\")\n",
        "        return\n",
        "\n",
        "    assigned_clusters = cluster_ids[valid_indices]\n",
        "    assigned_labels   = labels[valid_indices]\n",
        "\n",
        "    #Build cluster->(label counts)\n",
        "    cluster_label_counts = defaultdict(Counter)\n",
        "    for i, c in zip(valid_indices, assigned_clusters):\n",
        "        lbl = labels[i]\n",
        "        cluster_label_counts[c][lbl] += 1\n",
        "\n",
        "    #Count total occurrences of each label\n",
        "    total_label_count = Counter(assigned_labels)\n",
        "\n",
        "    #For each label => best cluster\n",
        "    unique_labels = sorted(set(assigned_labels))\n",
        "    best_cluster_for_label = {}\n",
        "    for L in unique_labels:\n",
        "        best_cid = None\n",
        "        best_count = 0\n",
        "        for cid, lbl_counter in cluster_label_counts.items():\n",
        "            c_count = lbl_counter[L]\n",
        "            if c_count > best_count:\n",
        "                best_count = c_count\n",
        "                best_cid   = cid\n",
        "        best_cluster_for_label[L] = (best_cid, best_count)\n",
        "\n",
        "    #Compute per-label accuracy\n",
        "    label_accuracies = {}\n",
        "    for L in unique_labels:\n",
        "        best_cid, best_count_for_L = best_cluster_for_label[L]\n",
        "        total_L = total_label_count[L]\n",
        "        if total_L > 0:\n",
        "            label_acc = best_count_for_L / total_L\n",
        "        else:\n",
        "            label_acc = 0.0\n",
        "        label_accuracies[L] = label_acc\n",
        "\n",
        "    #Plot a bar chart of these per-label accuracies\n",
        "    lbls_sorted = sorted(label_accuracies.keys())\n",
        "    acc_values  = [label_accuracies[L] for L in lbls_sorted]\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.bar([str(lbl) for lbl in lbls_sorted], acc_values, color='purple')\n",
        "    plt.ylim([0, 1])\n",
        "    plt.xlabel(\"Label (Class)\")\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Per-Label Accuracy (Largest Cluster Assignment)\")\n",
        "    plt.show()\n",
        "\n",
        "    #Print numeric results & overall accuracy\n",
        "    overall_correct = 0\n",
        "    overall_total   = 0\n",
        "    for L in lbls_sorted:\n",
        "        best_cid, best_count_for_L = best_cluster_for_label[L]\n",
        "        total_L = total_label_count[L]\n",
        "        overall_correct += best_count_for_L\n",
        "        overall_total   += total_L\n",
        "        print(f\"Label {L}: best_cluster={best_cid}, correct={best_count_for_L}, total={total_L}, acc={label_accuracies[L]:.4f}\")\n",
        "\n",
        "    overall_acc = overall_correct / overall_total if overall_total > 0 else 0.0\n",
        "    print(f\"\\nOverall Accuracy (sum of per-label correct / total) = {overall_acc:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "evaluate_class_accuracy(manager)\n",
        "plot_class_accuracy(manager)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:PyTorch]",
      "language": "python",
      "name": "conda-env-PyTorch-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}